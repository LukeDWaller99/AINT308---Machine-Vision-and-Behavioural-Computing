\documentclass[conference]{IEEEtran}

\renewcommand{\familydefault}{\sfdefault}

\usepackage{graphicx}
\usepackage{caption}
\usepackage{subfigure}
\usepackage{float}
\usepackage{indentfirst}
\usepackage[compact]{titlesec}
\setlength{\parindent}{11pt}
\newcommand{\forceindent}{\leavevmode{\parindent=1em\indent}}

\hyphenation{op-tical net-works semi-conduc-tor}

\graphicspath{{images/}}

\usepackage{hyperref}

\hypersetup
{
    colorlinks=true,
    linkcolor=black,   
    urlcolor=blue,
    citecolor=black,
}

\makeatletter
\def\endthebibliography{%
  \def\@noitemerr{\@latex@warning{Empty `thebibliography' environment}}%
  \endlist
}
\makeatother

\begin{document}



\title{AINT308 - OpenCV Assignment 2 2022}

\author{\IEEEauthorblockN{Student No. 10618407}
\IEEEauthorblockA{School of Engineering,\\Computing and Mathematics
\\University of Plymouth\\
Plymouth, Devon\\}}

\maketitle

\begin{abstract}

Machine vision is a mature technology that is becoming more prevalent within modern engineering practises. It is being utilised more in the rapidly evolving fields of autonomy and automation. This report outlines some of the functionalities of a popular C/C++ based computer visions library \href{https://opencv.org}{\textit{OpenCV}}. The Assignment has been split into two tasks; Task 4 and Task 5. The first task, Task 4, is Disparity Mapping using a pair of stereo cameras to be able to judge distances to objects. The second task, Task 5, was Self-driving Car Lane Detection from the dashcam footage taken from a car.

\end{abstract}

\subsection*{Keywords:} 
Computer Vision, OpenCV, Object Detection, C++, Lane Detection

\section{Task 4: Disparity Mapping}	
\subsection{Introduction}

The first task was to perform disparity mapping to evaluate the distance of a given object in a frame to allow a robot to navigate it's environment. Disparity Mapping allows the robot to build up a 3D view of it's environment  

\subsection{Solution}

The solution to this task was split up into multiple parts. Firstly, using the calibration images to calibrate the cameras. Secondly, using the calibration result to correct the stereo distance targets. Next, Combining the left and right images into a disparity map, with brightness indicating the distance from the camera. Penultimately, labelling the distance targets with their known distance to the camera. Use this to plot disparity against distance and write a formula relating distance to disparity. Finally, using the formula to calculate the distance for each of the unknown targets.

\subsubsection{Camera Calibration and Stereo Image Correction}

Stereo camera needs to be calibrated to one another before they can be used for stereo vision. Corrections need to be made for both physical misalignments (extrinsic error), and lens distortion(intrinsic error) \cite{Stero_Calibration}. This was done using the \href{https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html?highlight=stereocalibration}\textit{SteroCalibration} program provided by \textit{OpenCV} \cite{Book_Calibration}.

The program firstly reads in image pairs (taken from the left and right camera) of a checkerboard pattern target placed in different locations and orientations. This allows the program to create a list of intrinsics and extrinsic parameters to allow for these effects in the program. The checkerboard is of known size so the program can calibrate what it sees against what it is expecting. This known as the Bouquet stereo image calibration \cite{Bouget}.

\subsubsection{Disparity Mapping} \label{Disparity_Mapping}

The first stage of disparity mapping was to remap the images to correct for the positional/lens distortion, as mentioned above \cite{OpenCV_Remapping}. The two images were then combined into a 16 bit stereo block matcher \cite{Stereo_Block_Matching}. The code for doing this can be found in Fig \ref{fig:ImageRemapping}.

\begin{figure}[H]
\centerline{\includegraphics[width=.4\textwidth]{ImageRemapping}}
\caption{Remapping Left and Right Images into one image}
\label{fig:ImageRemapping}
\end{figure}

Once this was done, a 16 bit disparity map of the two images has been created. To measure the disparity, a rectangular region of interest was created, as seen in fig \ref{fig:RectangleOnDisparityMap}. This was created to make sure that only the disparity of the measured object was used. Whilst in the actual test the disparity map used was the 16-bit version, it does not get outputted correctly, so the 8-bit version is used for demonstration purposes.

\begin{figure}[H]
\centerline{\includegraphics[width=.4\textwidth]{RectangleOnDisparityMap}}
\caption{Rectangle Drawn On Disparity Map to Indicate Search Area}
\label{fig:RectangleOnDisparityMap}
\end{figure}

Fig \ref{Disparity_Mapping} is the main code to check the disparity for this task. The code is searching through all of the pixels in a given area (as constructed in fig \ref{fig:RectangleOnDisparityMap}). If the disparity value is larger than a certain value, it is added to the list. 

\begin{figure}[H]
\centerline{\includegraphics[width=.4\textwidth]{DisparityMappingCode}}
\caption{Disparity Mapping Code for evaluating the disparity in a image}
\label{fig:DisparityMappingCode}
\end{figure}

At the end of the run, the average value of the disparity is found, this is shown in fig \ref{fig:DistanceOutputKnownDistances}. These values were saved to a CSV files for evaluation after execution. 

\subsubsection{Labelling Known Distances and Creating Disparity Function}

From the values of measured distance and disparity shown in table \ref{table:distance_and_disparity_tables}. The graph in fig \ref{fig:DisparityGraph} was created to map the disparity over distance.

\begin{figure}[H]
\centerline{\includegraphics[width=.4\textwidth]{DisparityGraph}}
\caption{Graph of Disparity over Distance }
\label{fig:DisparityGraph}
\end{figure} 

Fig \ref{fig:DisparityGraph} has been made using the data from table \ref{table:distance_and_disparity_tables}. The value for $Bf$ was calculated by rearranging the disparity equation \ref{eq:Disparity_Equation} to equation \ref{eq:Disparity_Equation_rearranged_1}. To do this, the average of the $Distance \cdot Disparity$ was taken, as shown in equation \ref{eq:AverageDisparity}. 

\begin{equation} \label{eq:Disparity_Equation}
Disparity = \frac{B \cdot f}{Distance}
\end{equation}

\begin{equation} \label{eq:Disparity_Equation_rearranged_1}
B \cdot f = Disparity \cdot Distance
\end{equation}

\begin{equation} \label{eq:AverageDisparity}
\frac{Distance \cdot Disparity}{Total Number of Values}
\end{equation}

\begin{table}
\begin{center}
\caption{Distance and Disparity Table}
\begin{tabular}{ || c || c || c || }
\hline
 Measured Distance & Disparity Value & Distance x Disparity\\ 
\hline
 30 & 2089.72 & 62691.6 \\  
\hline
 40 & 1566 & 62640 \\  
\hline
 50 & 1240.27 & 62013.5 \\  
\hline
 60 & 1026.87 & 61612.2 \\  
\hline
 70 & 896.546 & 62758.22 \\  
\hline
 80 & 782.35 & 62588 \\  
\hline
 90 & 703.714 & 63334.26 \\  
\hline
 100 & 626.804 & 62680.4 \\  
\hline
 110 & 558.514 & 61436.54 \\  
\hline
 120 & 483.93 & 58071.6 \\  
\hline
 130 & 449.154 & 58390.02 \\  
\hline
 140 & 421.226 & 58971.64 \\  
\hline
 150 & 396.406 & 59460.9 \\  
\hline

\end{tabular}
\label{table:distance_and_disparity_tables}
\end{center}
\end{table}

Once the value of $Bf$ had been found it was used to calculate the the distances for the known targets, as of test of the previous measurements accuracy this can be seen in equation \ref{eq:Disparity_Equation_rearranged_1}. The code for calculating the distance and outputting the result can be seen in fig \ref{fig:DistanceOutputKnownDistances}.

\begin{figure}[H]
\centerline{\includegraphics[width=.4\textwidth]{DistanceOutputKnownDistances}}
\caption{Code to output the distance measured to the object}
\label{fig:DistanceOutputKnownDistances}
\end{figure}

From the values of measured distance and disparity shown in table \ref{table:distance_values_for_known_values}, and the accuracy of the prediction was also recorded. As the distance value for the testing images was already known and the disparity value had just been calculated, it was easy to test the output of the equation for reliability and accuracy.

\begin{table}
\begin{center}
\caption{Distance Calculated from Disparity Mapping with Known Distances}
\begin{tabular}{ || c || c || c || }
\hline
 Measured Distance & Calculated Distance & \% Difference\\ 
\hline
 30 & 29.32 & 2.25 \\  
\hline
 40 & 39.13 & 2.17 \\  
\hline
 50 & 49.41 & 1.18 \\  
\hline
 60 & 59.68 & 0.54 \\  
\hline
 70 & 68.35 & 2.36 \\  
\hline
 80 & 78.35 & 2.10 \\  
\hline
 90 & 87.08 & 3.24 \\  
\hline
 100 & 97.77 & 2.23 \\  
\hline
 110 & 109.72 & 0.25 \\  
\hline
 120 & 126.63 & -5.53 \\  
\hline
 130 & 136.43 & -4.95 \\  
\hline
 140 & 145.48 & -3.91 \\  
\hline
 150 & 154.59 & -3.06 \\  
\hline

\end{tabular}
\label{table:distance_values_for_known_values}
\end{center}
\end{table}

\subsubsection{Using Disparity Formula to calculate distances for unknown targets} 
To find the distance for the unknown targets, the disparity value was firstly calculated using the same method as described above. The disparity value, along with the value previously calculated using equation \ref{eq:Disparity_Equation_rearranged_1}, can be used to calculated the distance of the object in the images. 

The method for evaluating the distances of the objects in the images was very similar to the function used in,  within the Disparity Mapping section. The main differences between the two codes are, the source of the files and the terminal output of the program. The files used in calculating the distance were images with an unknown distance to the object in the image. The output in the terminal was almost identical but the known distance of the object was not stated - as it was unknown. 

It is unclear how close the  the estimates of distance were to the actual values but given the accuracy on the known images (within 5.53\%), it would be safe to assume that these values could be considered accurate within a 6\% margin.

\subsection{Further Improvements}

Although this method was effective there are still ways in which it could be improved. The two biggest flaws with this method was how the calibration was conducted.

The distance measurement was conducted using a a box held aloft over a ruler. Whilst this did provide adequate calibration data for the disparity testing, it could have been conducted in a manor that would have made the measurements increasingly more precise. 

A clearer background would have been beneficial for disparity matching. The utilised background had lots of moving objects that were not consistent between images. This required a region of interest to be used for the disparity mapping. This resulted in a smaller area for the disparity to be measured across. Ideally a plain background would have been used to allow a larger amount of the frame to be mapped. This would increase the area for the disparity mapping thus reducing the effect of outliers within the region of interest. 

These were the two biggest areas of uncertainty in this method and thus would gain the best yield if improved.

\subsection{Conclusion}
Overall this task was hard to judge on the unknown data, as the results were not known and thus hard to tell the accuracy of the finalised results. Despite this, the known measurement disparity mapping was extremely successful, with a maximum error of 5.53\% and an average error of only 2.9\%. Although the methodology could have been improved by making the calibration data collection more precise and using a clearer background, the distances of measurement used (30cm-150cm) would negate the effects of measurement over that distance. 

\section{Task 5: Self-driving Car Lane Detection}

\subsection{Introduction}

The second task was to track the lanes in dashcam footage from the front of a car driving on the road. This is one of the most complex computer vision applications within the field of autonomous cars. Mordern cars have a plethora of cars around their circumference, this allows them to capture large amounts of data whilst on the road. The real difficulty with this is how to break down the information into smaller useful chunks.  

\subsection{Solution}
\subsection{Further Improvements}
\subsection{Conclusion}

\bibliographystyle{IEEEtran}
\bibliography{refs}

The code can be found on GitHub \href{https://github.com/LukeDWaller99/Aint308}{here!} 

\onecolumn

\begin{appendix}

\end{appendix}

\end{document}
